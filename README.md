# Архиватор изображений с использованием модели Автокодировщика

Задача сжатия изображения с использованием ML заключается в том, что обучить модель кодировать поданное ей на вход
изображение в скрытое пространство и затем обратно декодировать.
Чем больше итоговое изображение после такой операции похоже на изначальное - тем лучше.

Для решения этой задачи была выбрана архитектура модели автокодировщик, которая состоит из двух блоков - энкодера и
декодера.
Так как предполагается, что закодированное энкодером изображение нужно сохранять на диск, то необходимо использовать
квантизацию для отображения пространства чисел с плавающей точкой в целые числа.
При процессе квантизации часть информации теряется.
Количество потерянной информации зависит от того, какая точность (уровень квантизации) была выбрана.
При декодировании изображения нужно учитывать эти помехи, поэтому на этапе обучения обучается декодер, принимающий на
вход искусственно зашумленное закодированное изображение.

Для уменьшения размера файла закодированное изображение сжимается с использованием адаптивного арифметического
кодирования.

## Подробная архитектура модели

Весь автокодировщик представляет собой полносверточную сеть (т.е. из базовых блоков используются только операции
свертки, без линейных слоев) и способен обрабатывать изображения любого размера. Однако изображения с нечетными
размерностями сжимаются и разжимаются некорректно (добавляется небольшой паддинг к изображению) из-за нечетности.

### Энкодер

В качестве энкодера можно было бы взять уже предобученный на датасете ImageNet бекбон модели ResNet (или любой другой,
например, VGG, Inception, MobileNet и т.п.), однако предварительное обучение автокодировщика показало, что скрытое
пространство этих моделей не очень удачно использовать для задачи сжатия изображения.

В итоге было принято решение создать свой ResNet-подобный энкодер, использующий такие техники как skipconnection и
свертки с ядром 1х1.

Еще одно наблюдение: во всех стандартных моделях первый слой после свертки выполняет операцию `MaxPool2d(kernel_size=3,
stride=2, padding=1)`, которая является необучаемой и намеренно теряет часть информации. Я решил, что вместо неё лучше
использовать обучаемую свертку.

В процессе кодирования увеличивается количество каналов сжимаемого изображения, при этом уменьшение размерности
изображения зависит от количества используемых слоев. В своей работе я тестировал сжатие 5-ю и 6-ю слоями (`low`
и `high` степени сжатия соответственно) с постепенным
выходом на 512 каналов. Использование 5-ти слоев приводит к сжатию каждой размерности в `2^5=32` раза, а 6-ти слоёв
в `2^6=64` раза. Таким образом, изображение `3x512x512` в первом случае будет сжато в `512x16x16` (разница с изначальным
в 6 раз), а во втором случае в `512x8x8` (разница в 24 раза).

При обучении размер входного изображения был `256x256`.

### Квантизация и деквантизация

#### Квантизация при обучении

В процессе обучения модели нужно учитывать возможные потери информации при сохранении закодированного изображения на
диск. Поэтому при обучении к закодированному изображению дополнительно добавляется шум, величина которого зависит от
выбранного уровня квантизации.
Формула шума квантизации при обучении с уровнем квантизации `B`:
`noise = sample_from_normal_dist(mean=-0.5, std=0.5, size=encoded.shape) * math.pow(2, -B)`

#### Квантизация во время инференса

Во время реального использования модели шум возникнет сам при переводе чисел с плавающей точкой в целые числа.
Формула перевода следующая:
`(encoded * math.pow(2, B) + 0.5).cast_to_int()`

#### Деквантизация во время инференса

Во время реального использования для последующей передачи в декодер закодированного изображения его нужно
деквантизировать.
Формула деквантизации:
`encoded.cast_to_float() / math.pow(2, B)`

### Сжатие закодированного изображения

Для сжатия закодированного изображения используется адаптивное арифметическое кодирование, которое позволяет сжимать
данные без потери информации.

Библиотека с реализованным ААК: [arithmetic-compressor](https://github.com/kodejuice/arithmetic-compressor).

Перед подачей в кодер закодированных данных, их нужно преобразовать из многомерного вида (CxHxW) в одномерный вид, для
этого просто используется операция `flatten()`.

Результатом сжатия является список бит (0/1), которые образуют число, характеризующее изначальные входные данные.

### Сохранение информации на диск

После сжатия данных список бит (0/1) нужно сохранить на диск в файл. Для этого используется
библиотека [bitarray](https://github.com/ilanschnell/bitarray).

Помимо собственно данных, в итоговый файл также записывается информация об изначальной многомерной размерности входных
данных, количество используемых бит и использованный уровень квантизации.

### Декодер

Декодирование производится с постепенным уменьшением количества каналов с 512 до 3, и с постепенным удвоением
размерности до исходной размерности изображения.

Для обратного повышения размерности можно использовать два блока - `nn.Upsampling` и `nn.Conv2dTranspose`. Первый блок
является необучаемым, а второй обучаемым. В блоках декодера специально заданы две ветки, в каждой из которых
используется один из этих подходов. Этим действием мы разрешаем модели самой выбрать какой из подходов ей выгоднее
использовать.

## Обучение модели

### Датасеты

В работе использовались 3 датасета: [ColorizedMNIST](https://github.com/jayaneetha/colorized-MNIST) для проверки
минимальной работоспособности моделей и [ImageNet-mini](https://www.kaggle.com/datasets/ifigotin/imagenetmini-1000)
и [ImageNet130K](https://www.kaggle.com/datasets/rhtsingh/130k-images-512x512-universal-image-embeddings?resource=download)
для полноценного обучения моделей.

В качестве аугментации при обучении используются следующие трансформации:

```
train_data_transforms = T.Compose([
        T.Resize((256, 256)),
        T.RandomHorizontalFlip(),
        T.RandomVerticalFlip(),
        T.ToTensor(),
    ])
```

### Функция потерь

В качестве функции потерь используется MSE, однако я также проводил эксперименты с
лоссом [SmoothL1Loss](https://pytorch.org/docs/stable/generated/torch.nn.SmoothL1Loss.html), но значительной разницы не
заметил.

Дополнительно можно было использовать LPIPS лосс, однако использование VGG в качестве бекбона для подсчета этого лосса
занимает очень много оперативной памяти видеокарты, поэтому LPIPS использован не был.

### Оптимизатор

[Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html) был использован в качестве оптимизатора.
Также значительное улучшение качества обучения было получено с
использованием [StepLRScheduler](https://pytorch.org/docs/stable/generated/torch.optim.lr_scheduler.StepLR.html).
Этот шедулер постепенно понижает коэффициент скорости обучения.
Начальный LR равен `0.01`, затем после каждых двух эпох LR умножается на `0.4`.
Обучение длится не более `20` эпох.

## Результаты

### Метод оценки

Для оценки результатов реализованных моделей сжатия можно провести сравнение с другим очень популярным методом сжатия
изображения - JPEG'ом.

При оценке потребуются следующие метрики:

* `BPP` - bits per pixel.
  BPP отражает насколько сильно изображение было сжато.
  Чем ниже BPP, тем сильнее сжатие.
  Формула BPP: `filesize_in_bytes(img) * 8 / (img.height * img.width * img.channels)`.
  Так как в работе используются трехканальные (RGB) изображения, то `img.channels` в формуле опущено.
* `PSNR` - Peak signal-to-noise ratio.
  PSNR отражает качество сжатого изображения в сравнении с исходным изображением.
  PSNR является аналогом MSE и вычисляется через него, однако наоборот, чем PSNR выше, тем сжатое изображение более
  похоже на изначальное.
  Формула для подсчета PSNR: `-10 * log10(mse(img1, img2))`, при учете, что `img1` и `img2` отнормированы в
  промежуток \[0, 1\].

Метод оценки состоит в следующем.

1. Нужно сжать входное изображение реализованным методом, сохранить его на диск,
   посчитать его BPP, затем продекодировать и посчитать PSNR полученного изображения с исходным.
2. Затем нужно подобрать такой коэффициент сжатия с помощью JPEG, чтобы полученное изображение имело такой же BPP, как у
   тестируемого метода.
3. Затем нужно посчитать PSNR для сжатого JPEG-изображения.
4. Чем выше PSNR тестируемого метода, тем лучше. Превышение PSNR тестируемого метода над PSNR у JPEG будет означать, что
   тестируемый метод сжимает лучше, чем JPEG.

### Сравнительные таблицы и графики

(*) Больше сравнительных данных и логи обучения можно посмотреть [здесь](./doc_images).

#### 5-ти слойная low-compression модель

Скрытое пространство для изображения 3x512x512 равно 512x16x16.

##### Оценка модели, обученной с использованием квантизации (B=2)

| JPEG Q/BPP/PSNR |                                                       JPEG                                                       | AE BPP/PSNR |                                                  AutoEncoder                                                   |
|----------------:|:----------------------------------------------------------------------------------------------------------------:|-------------|:--------------------------------------------------------------------------------------------------------------:|
|   14/0.79/22.65 |  ![baboon_B_2_best_bpp.jpg](doc_images%2Flow_comp_model%2Ftrained_with_B%3D2%2FB%3D2%2Fbaboon_B_2_best_bpp.jpg)  | 0.77/15.79  |  ![baboon_decoded_B_2.png](doc_images%2Flow_comp_model%2Ftrained_with_B%3D2%2FB%3D2%2Fbaboon_decoded_B_2.png)  |
|   35/0.75/32.02 |    ![lena_B_2_best_bpp.jpg](doc_images%2Flow_comp_model%2Ftrained_with_B%3D2%2FB%3D2%2Flena_B_2_best_bpp.jpg)    | 0.76/18.04  |    ![lena_decoded_B_2.png](doc_images%2Flow_comp_model%2Ftrained_with_B%3D2%2FB%3D2%2Flena_decoded_B_2.png)    |
|   30/0.77/30.10 | ![peppers_B_2_best_bpp.jpg](doc_images%2Flow_comp_model%2Ftrained_with_B%3D2%2FB%3D2%2Fpeppers_B_2_best_bpp.jpg) | 0.77/16.87  | ![peppers_decoded_B_2.png](doc_images%2Flow_comp_model%2Ftrained_with_B%3D2%2FB%3D2%2Fpeppers_decoded_B_2.png) |

Графики обучения:

![loss_graph.png](doc_images%2Flow_comp_model%2Ftrained_with_B%3D2%2Floss_graph.png)
![psnr_graph.png](doc_images%2Flow_comp_model%2Ftrained_with_B%3D2%2Fpsnr_graph.png)

##### Оценка модели, обученной с использованием квантизации (B=8)

| JPEG Q/BPP/PSNR |                                                       JPEG                                                       | AE BPP/PSNR |                                                  AutoEncoder                                                   |
|----------------:|:----------------------------------------------------------------------------------------------------------------:|-------------|:--------------------------------------------------------------------------------------------------------------:|
|   50/1.98/25.53 |  ![baboon_B_8_best_bpp.jpg](doc_images%2Flow_comp_model%2Ftrained_with_B%3D8%2FB%3D8%2Fbaboon_B_8_best_bpp.jpg)  | 1.98/20.28  |  ![baboon_decoded_B_8.png](doc_images%2Flow_comp_model%2Ftrained_with_B%3D8%2FB%3D8%2Fbaboon_decoded_B_8.png)  |
|   82/1.91/34.93 |    ![lena_B_8_best_bpp.jpg](doc_images%2Flow_comp_model%2Ftrained_with_B%3D8%2FB%3D8%2Flena_B_8_best_bpp.jpg)    | 1.91/27.89  |    ![lena_decoded_B_8.png](doc_images%2Flow_comp_model%2Ftrained_with_B%3D8%2FB%3D8%2Flena_decoded_B_8.png)    |
|   79/1.94/32.93 | ![peppers_B_8_best_bpp.jpg](doc_images%2Flow_comp_model%2Ftrained_with_B%3D8%2FB%3D8%2Fpeppers_B_8_best_bpp.jpg) | 1.96/25.90  | ![peppers_decoded_B_8.png](doc_images%2Flow_comp_model%2Ftrained_with_B%3D8%2FB%3D8%2Fpeppers_decoded_B_8.png) |

Графики обучения:

![loss_graph.png](doc_images%2Flow_comp_model%2Ftrained_with_B%3D8%2Floss_graph.png)
![psnr_graph.png](doc_images%2Flow_comp_model%2Ftrained_with_B%3D8%2Fpsnr_graph.png)

#### 6-ти слойная high-compression модель

Скрытое пространство для изображения `3x512x512` равно `512x8x8`.

##### Оценка модели, обученной с использованием квантизации (B=2)

| JPEG Q/BPP/PSNR |                                                       JPEG                                                        | AE BPP/PSNR |                                                   AutoEncoder                                                   |
|----------------:|:-----------------------------------------------------------------------------------------------------------------:|-------------|:---------------------------------------------------------------------------------------------------------------:|
|    1/0.29/18.55 |  ![baboon_B_2_best_bpp.jpg](doc_images%2Fhigh_comp_model%2Ftrained_with_B%3D2%2FB%3D2%2Fbaboon_B_2_best_bpp.jpg)  | 0.19/15.28  |  ![baboon_decoded_B_2.png](doc_images%2Fhigh_comp_model%2Ftrained_with_B%3D2%2FB%3D2%2Fbaboon_decoded_B_2.png)  |
|    1/0.27/21.59 |    ![lena_B_2_best_bpp.jpg](doc_images%2Fhigh_comp_model%2Ftrained_with_B%3D2%2FB%3D2%2Flena_B_2_best_bpp.jpg)    | 0.19/16.26  |    ![lena_decoded_B_2.png](doc_images%2Fhigh_comp_model%2Ftrained_with_B%3D2%2FB%3D2%2Flena_decoded_B_2.png)    |
|    1/0.28/21.47 | ![peppers_B_2_best_bpp.jpg](doc_images%2Fhigh_comp_model%2Ftrained_with_B%3D2%2FB%3D2%2Fpeppers_B_2_best_bpp.jpg) | 0.19/14.94  | ![peppers_decoded_B_2.png](doc_images%2Fhigh_comp_model%2Ftrained_with_B%3D2%2FB%3D2%2Fpeppers_decoded_B_2.png) |

Графики обучения:

![loss_graph.png](doc_images%2Fhigh_comp_model%2Ftrained_with_B%3D2%2Floss_graph.png)
![psnr_graph.png](doc_images%2Fhigh_comp_model%2Ftrained_with_B%3D2%2Fpsnr_graph.png)

##### Оценка модели, обученной с использованием квантизации (B=8)

| JPEG Q/BPP/PSNR |                                                       JPEG                                                        | AE BPP/PSNR |                                                   AutoEncoder                                                   |
|----------------:|:-----------------------------------------------------------------------------------------------------------------:|-------------|:---------------------------------------------------------------------------------------------------------------:|
|   12/0.71/22.30 |  ![baboon_B_8_best_bpp.jpg](doc_images%2Fhigh_comp_model%2Ftrained_with_B%3D8%2FB%3D8%2Fbaboon_B_8_best_bpp.jpg)  | 0.71/19.02  |  ![baboon_decoded_B_8.png](doc_images%2Fhigh_comp_model%2Ftrained_with_B%3D8%2FB%3D8%2Fbaboon_decoded_B_8.png)  |
|   32/0.71/31.79 |    ![lena_B_8_best_bpp.jpg](doc_images%2Fhigh_comp_model%2Ftrained_with_B%3D8%2FB%3D8%2Flena_B_8_best_bpp.jpg)    | 0.71/24.73  |    ![lena_decoded_B_8.png](doc_images%2Fhigh_comp_model%2Ftrained_with_B%3D8%2FB%3D8%2Flena_decoded_B_8.png)    |
|   26/0.71/29.68 | ![peppers_B_8_best_bpp.jpg](doc_images%2Fhigh_comp_model%2Ftrained_with_B%3D8%2FB%3D8%2Fpeppers_B_8_best_bpp.jpg) | 0.71/22.41  | ![peppers_decoded_B_8.png](doc_images%2Fhigh_comp_model%2Ftrained_with_B%3D8%2FB%3D8%2Fpeppers_decoded_B_8.png) |

Графики обучения:

![loss_graph.png](doc_images%2Fhigh_comp_model%2Ftrained_with_B%3D8%2Floss_graph.png)
![psnr_graph.png](doc_images%2Fhigh_comp_model%2Ftrained_with_B%3D8%2Fpsnr_graph.png)

### Запуск

Веса моделей нужно скачать по [ссылке](https://mega.nz/file/5I9RlAAZ#TTbxvvFUMjA50lJVTX1Df_Np7aGEsw4FxM4U0k3LcyE) и их
следует положить в папку `models`.

В загруженном архиве также лежат веса моделей, обученных как с использованием квантизации с разными уровнями
квантизации, так и без.

#### Сжатие изображения

Пример запуска скрипта для сжатия изображения:

`python compress_image.py --image_path '.\test_images\lena.png' --output_dir 'compressed_images' --B 8 --comp 'low'`

#### Декодирование изображения

Пример запуска скрипта для декодирования сжатого изображения:

`python .\decompress_image.py --bin_file_path '.\compressed_images\lena_B_8_comp_low.bin' --output_dir 'decompressed_images' --B 8 --comp 'low'`

#### Запуск обучения модели

Для запуска обучения модели в Docker нужно предварительно сбилдить образ по Dockerfile с помощью
команды `docker_build_image.sh`.

После этого можно запускать обучение командой `docker_run_container.sh`.
Эта команда запустит файл `train.py`. Этот файл можно предварительно модифицировать, например, указать пути к датасетам
и параметры обучения модели.
